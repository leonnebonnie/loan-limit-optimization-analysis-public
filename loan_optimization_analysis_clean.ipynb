{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a2296f",
   "metadata": {},
   "source": [
    "# Loan Limit Optimization â€” Clean Notebook\n",
    "This notebook is a runnable conversion of `loan_optimization_analysis_clean.py`.\n",
    "It preserves the original logic but is split into cells for clarity: data loading, feature engineering, model training, optimization, simulation, and saving results.\n",
    "Random seed is fixed (42) for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and global setup\n",
    "import os\n",
    "import random\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (kept same as original)\n",
    "PROFIT_PER_INCREASE = 40\n",
    "MAX_INCREASES_PER_YEAR = 6\n",
    "DISCOUNT_RATE = 0.19\n",
    "ELIGIBILITY_THRESHOLD_DAYS = 60\n",
    "\n",
    "# Default file names\n",
    "INPUT_FILE = 'loan_limit_increases.xlsx'\n",
    "OUT_RESULTS = 'loan_optimization_results.csv'\n",
    "OUT_RECOMM = 'recommended_increases.csv'\n",
    "OUT_SIM = 'simulation_results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78943de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load Excel data and normalize header if needed.\n",
    "    Returns a DataFrame with numeric conversion where appropriate.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Input file not found: {path}\")\n",
    "    df = pd.read_excel(path, skiprows=0)\n",
    "    if 'Customer ID' not in df.columns:\n",
    "        first_row = df.iloc[0].astype(str).str.lower()\n",
    "        if first_row.str.contains('customer id').any():\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df.iloc[1:].reset_index(drop=True)\n",
    "    for col in df.columns:\n",
    "        if col != 'Customer ID':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa2105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['Eligible'] = (df['Days Since Last Loan'] >= ELIGIBILITY_THRESHOLD_DAYS).astype(int)\n",
    "    df['Received_Increase'] = (df['No. of Increases in 2023'] > 0).astype(int)\n",
    "    def assign_risk(payment_rate):\n",
    "        if payment_rate >= 95: return 'Prime'\n",
    "        if payment_rate >= 85: return 'Near-Prime'\n",
    "        return 'Sub-Prime'\n",
    "    df['Risk_Category'] = df['On-time Payments (%)'].apply(assign_risk)\n",
    "    df['Loan_Size_Category'] = pd.cut(df['Initial Loan ($)'], bins=[0,1500,3000,5000], labels=['Small','Medium','Large'])\n",
    "    df['Credit_Score_Proxy'] = (\n",
    "        df['On-time Payments (%)'] * 0.6 +\n",
    "        (df['Days Since Last Loan'] / df['Days Since Last Loan'].max() * 100) * 0.2 +\n",
    "        ((df['Initial Loan ($)'] / df['Initial Loan ($)'].max()) * 100) * 0.2\n",
    "    )\n",
    "    df['Payment_Days_Interaction'] = df['On-time Payments (%)'] * df['Days Since Last Loan'] / 100\n",
    "    df['Loan_Payment_Ratio'] = df['Initial Loan ($)'] / (df['On-time Payments (%)'] + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_uptake_models(df: pd.DataFrame):\n",
    "    features = ['Initial Loan ($)','Days Since Last Loan','On-time Payments (%)','Credit_Score_Proxy','Payment_Days_Interaction','Loan_Payment_Ratio']\n",
    "    X = df[features]\n",
    "    y = df['Received_Increase']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "    lr = LogisticRegression(random_state=RANDOM_SEED, max_iter=1000)\n",
    "    lr.fit(X_train_sc, y_train)\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, max_depth=10)\n",
    "    rf.fit(X_train, y_train)\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_SEED, max_depth=5)\n",
    "    gb.fit(X_train, y_train)\n",
    "    models = {'Logistic Regression': (lr, X_test_sc), 'Random Forest': (rf, X_test), 'Gradient Boosting': (gb, X_test)}\n",
    "    best_name, best_auc, best_model = None, -1.0, None\n",
    "    for name, (model, Xt) in models.items():\n",
    "        try:\n",
    "            proba = model.predict_proba(Xt)[:,1]\n",
    "            auc = roc_auc_score(y_test, proba)\n",
    "        except Exception:\n",
    "            auc = 0.0\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_name = name\n",
    "            best_model = model\n",
    "    if best_name == 'Logistic Regression':\n",
    "        df['Uptake_Probability'] = lr.predict_proba(scaler.transform(df[features]))[:,1]\n",
    "    else:\n",
    "        df['Uptake_Probability'] = best_model.predict_proba(df[features])[:,1]\n",
    "    return best_name, best_auc, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f983837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_default_model(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['Default_Risk_Score'] = (\n",
    "        (100 - df['On-time Payments (%)']) * 0.5 +\n",
    "        (100 - df['Credit_Score_Proxy']) * 0.3 +\n",
    "        (df['Initial Loan ($)'] / df['Initial Loan ($)'].max() * 100) * 0.2\n",
    "    )\n",
    "    df['Default_Probability'] = 1 / (1 + np.exp(-0.1 * (df['Default_Risk_Score'] - 50)))\n",
    "    df['Adjusted_Default_Probability'] = df['Default_Probability'] * (1 + 0.05 * df['No. of Increases in 2023'])\n",
    "    df['Adjusted_Default_Probability'] = df['Adjusted_Default_Probability'].clip(0, 0.95)\n",
    "    return df\n",
    "\n",
    "def calculate_expected_value(row):\n",
    "    uptake_prob = row['Uptake_Probability']\n",
    "    default_prob = row['Adjusted_Default_Probability']\n",
    "    expected_profit = PROFIT_PER_INCREASE * uptake_prob * (1 - default_prob)\n",
    "    expected_loss = row['Initial Loan ($)'] * 0.5 * uptake_prob * default_prob\n",
    "    return expected_profit - expected_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_loan_increases(df_input, max_high_risk_pct=0.25, capital_constraint=None):\n",
    "    eligible = df_input[df_input['Eligible'] == 1].copy()\n",
    "    eligible = eligible.sort_values('Risk_Adjusted_Score', ascending=False)\n",
    "    eligible['Recommended_Increases'] = 0\n",
    "    eligible['Total_Expected_Value'] = 0.0\n",
    "    total_value = total_exposure = 0.0\n",
    "    high_risk_count = total_approvals = 0\n",
    "    for idx, row in eligible.iterrows():\n",
    "        is_high_risk = row['Risk_Category'] == 'Sub-Prime'\n",
    "        if is_high_risk and high_risk_count >= len(eligible) * max_high_risk_pct:\n",
    "            continue\n",
    "        if row['Expected_Value'] <= 0:\n",
    "            continue\n",
    "        optimal_increases = min(MAX_INCREASES_PER_YEAR, int(row['Uptake_Probability'] * MAX_INCREASES_PER_YEAR) + 1)\n",
    "        if capital_constraint:\n",
    "            projected_exposure = row['Initial Loan ($)'] * optimal_increases * 0.5\n",
    "            if total_exposure + projected_exposure > capital_constraint:\n",
    "                continue\n",
    "        eligible.at[idx, 'Recommended_Increases'] = optimal_increases\n",
    "        eligible.at[idx, 'Total_Expected_Value'] = float(row['Expected_Value']) * optimal_increases\n",
    "        total_value += eligible.at[idx, 'Total_Expected_Value']\n",
    "        total_exposure += row['Initial Loan ($)'] * optimal_increases * 0.5\n",
    "        if is_high_risk:\n",
    "            high_risk_count += 1\n",
    "        total_approvals += 1\n",
    "    return {'eligible_df': eligible, 'total_expected_value': total_value, 'total_approvals': total_approvals, 'total_exposure': total_exposure, 'high_risk_count': high_risk_count, 'high_risk_pct': high_risk_count / total_approvals if total_approvals > 0 else 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_loan_lifecycle(customer_row, n_simulations=100, time_periods=4):\n",
    "    results = []\n",
    "    transition_matrix = np.array([[0.85,0.12,0.03],[0.15,0.7,0.15],[0.05,0.25,0.7]])\n",
    "    risk_states = ['Prime','Near-Prime','Sub-Prime']\n",
    "    for sim in range(n_simulations):\n",
    "        total_profit = total_losses = 0.0\n",
    "        defaults = increases = 0\n",
    "        current_risk_state = customer_row['Risk_Category']\n",
    "        for quarter in range(time_periods):\n",
    "            if quarter > 0:\n",
    "                state_idx = {'Prime':0,'Near-Prime':1,'Sub-Prime':2}[current_risk_state]\n",
    "                probs = transition_matrix[state_idx]\n",
    "                next_state_idx = np.random.choice(3, p=probs)\n",
    "                current_risk_state = risk_states[next_state_idx]\n",
    "            risk_multiplier = {'Prime':0.8,'Near-Prime':1.0,'Sub-Prime':1.3}[current_risk_state]\n",
    "            adjusted_default_prob = min(customer_row['Default_Probability'] * risk_multiplier, 0.95)\n",
    "            accepts = np.random.random() < customer_row['Uptake_Probability']\n",
    "            if accepts:\n",
    "                increases += 1\n",
    "                if np.random.random() < adjusted_default_prob:\n",
    "                    defaults += 1\n",
    "                    total_losses += customer_row['Initial Loan ($)'] * 0.5\n",
    "                else:\n",
    "                    total_profit += PROFIT_PER_INCREASE\n",
    "        results.append({'simulation': sim, 'total_profit': total_profit, 'total_losses': total_losses, 'net_value': total_profit - total_losses, 'defaults': defaults, 'increases_granted': increases})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def calculate_npv(cash_flows, discount_rate=DISCOUNT_RATE):\n",
    "    npv = 0.0\n",
    "    for t, cf in enumerate(cash_flows):\n",
    "        npv += cf / ((1 + discount_rate) ** (t / 4))\n",
    "    return npv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RUN PIPELINE (example parameters) ===\n",
    "# Parameters: adjust as needed inside the notebook before re-running cells\n",
    "SIM_CUSTOMER_COUNT = 1000\n",
    "N_SIMULATIONS_PER_CUSTOMER = 100\n",
    "SIM_QUARTERS = 4\n",
    "\n",
    "# Load and prepare data\n",
    "df = load_data(INPUT_FILE)\n",
    "print('Dataset Shape:', df.shape)\n",
    "df = feature_engineering(df)\n",
    "print('Eligible Customers (>=60 days):', int(df['Eligible'].sum()))\n",
    "\n",
    "# Models\n",
    "best_name, best_auc, df = build_uptake_models(df)\n",
    "print('Best uptake model:', best_name, 'AUC=', round(best_auc,4))\n",
    "df = build_default_model(df)\n",
    "\n",
    "# Expected values and risk-adjusted score\n",
    "df['Expected_Value'] = df.apply(calculate_expected_value, axis=1)\n",
    "df['Risk_Adjusted_Score'] = df['Expected_Value'] * (1 - df['Adjusted_Default_Probability']) * df['Uptake_Probability']\n",
    "\n",
    "# Optimization\n",
    "optimization_results = optimize_loan_increases(df, max_high_risk_pct=0.25)\n",
    "print('Approved for Increases:', optimization_results['total_approvals'])\n",
    "print('Total Expected Value: $', round(optimization_results['total_expected_value'],2))\n",
    "\n",
    "# Monte Carlo sampling\n",
    "eligible_customers = df[df['Eligible'] == 1]\n",
    "available = len(eligible_customers)\n",
    "if SIM_CUSTOMER_COUNT <= available:\n",
    "    sample_customers = eligible_customers.sample(n=SIM_CUSTOMER_COUNT, random_state=RANDOM_SEED)\n",
    "else:\n",
    "    sample_customers = eligible_customers.sample(n=SIM_CUSTOMER_COUNT, replace=True, random_state=RANDOM_SEED)\n",
    "\n",
    "sim_list = []\n",
    "for _, row in sample_customers.iterrows():\n",
    "    sim_df = simulate_loan_lifecycle(row, n_simulations=N_SIMULATIONS_PER_CUSTOMER, time_periods=SIM_QUARTERS)\n",
    "    sim_df['customer_id'] = row['Customer ID']\n",
    "    sim_df['risk_category'] = row['Risk_Category']\n",
    "    sim_list.append(sim_df)\n",
    "all_simulations = pd.concat(sim_list, ignore_index=True)\n",
    "\n",
    "print('Total Simulation Runs:', SIM_CUSTOMER_COUNT * N_SIMULATIONS_PER_CUSTOMER)\n",
    "print('Total Individual Decisions:', SIM_CUSTOMER_COUNT * N_SIMULATIONS_PER_CUSTOMER * SIM_QUARTERS)\n",
    "print('Simulation sample mean net value:', round(all_simulations.groupby('customer_id')['net_value'].mean().mean(),2))\n",
    "\n",
    "# Save outputs\n",
    "df.to_csv(OUT_RESULTS, index=False)\n",
    "optimization_results['eligible_df'][optimization_results['eligible_df']['Recommended_Increases'] > 0][['Customer ID','Risk_Category','On-time Payments (%)','Initial Loan ($)','Uptake_Probability','Default_Probability','Expected_Value','Recommended_Increases','Total_Expected_Value']].to_csv(OUT_RECOMM, index=False)\n",
    "all_simulations.to_csv(OUT_SIM, index=False)\n",
    "print('Saved outputs:', OUT_RESULTS, OUT_RECOMM, OUT_SIM)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
